{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass\n",
    "from configuration import (\n",
    "    WIKIPEDIA_HOST_URL,\n",
    "    WIKIPEDIA_SEARCH_API\n",
    ")\n",
    "\n",
    "LOGGER_BASENAME = 'wikisearch'\n",
    "LOGGER = logging.getLogger(LOGGER_BASENAME)\n",
    "LOGGER.addHandler(logging.NullHandler())\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class LoggerMixin(object):\n",
    "    def __init__(self) -> None:\n",
    "        self._logger = logging.getLogger(f'{LOGGER_BASENAME}.{self.__class__.__name__}')\n",
    "\n",
    "class WikipediaSeries(LoggerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.search_url = WIKIPEDIA_SEARCH_API\n",
    "        self.seasons = []\n",
    "        self.title = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'series seasons: {self.seasons}'\n",
    "    \n",
    "    def _get_query_map(self, name):\n",
    "        query_map = {\n",
    "            'episode_list': f'list of {name} episodes',\n",
    "            'miniseries': f'{name} miniseries',\n",
    "            'name': f'{name}'\n",
    "        }\n",
    "        return query_map\n",
    "\n",
    "    def search_by_name(self, name):\n",
    "        for type, query in self._get_query_map(name).items():\n",
    "            self._logger.debug(f'Searching for {name} with type:{type}')\n",
    "            result = self._search(query)\n",
    "            if result:\n",
    "                if len(result) == 1:\n",
    "                    self.title = name\n",
    "                return result\n",
    "    \n",
    "    def _search(self, query):\n",
    "        parameters = {'action': 'opensearch',\n",
    "                            'format': 'json',\n",
    "                            'formatversion': '2',\n",
    "                            'search': query}\n",
    "\n",
    "        response = requests.get(self.search_url, params=parameters)\n",
    "        if response.ok:\n",
    "            return [SearchResult(*args) for args in zip(response.json()[1], response.json()[3])]\n",
    "        else:\n",
    "            self._logger.error(f'Request failed with code {response.code} and message {response.text}')\n",
    "        \n",
    "    \n",
    "    def get_soup_by_url(self, url):\n",
    "        html_response = requests.get(url)\n",
    "        soup = BeautifulSoup(html_response.text, 'html.parser')\n",
    "        return soup\n",
    "    \n",
    "    def parse_seasons_from_soup(self, soup):\n",
    "        season_list = []\n",
    "        table = soup.find(\"table\", {\"class\": \"wikitable plainrowheaders\"})\n",
    "        t_headers = table.find_all(\"th\")\n",
    "        for header in t_headers:\n",
    "            season = header.find(\"a\")\n",
    "            if season:\n",
    "                season_list.append(season.contents[0])\n",
    "        return season_list\n",
    "\n",
    "    def parse_seasons_and_episodes_from_soup(self, soup):\n",
    "        season_list = []\n",
    "        tables = soup.find_all(\"table\", {\"class\": \"wikitable plainrowheaders wikiepisodetable\"})\n",
    "        for table in tables:\n",
    "            episode_list = []\n",
    "            season_header = table.find_previous_sibling('h3')\n",
    "            season_title = season_header.find(\"span\", {\"class\": \"mw-headline\"}).contents[0]\n",
    "            season = Season(season_title)\n",
    "            episodes = table.find_all(\"tr\", {\"class\": \"vevent\"})\n",
    "            for episode in episodes:\n",
    "                episode_number = episode.find(\"td\").contents[0]\n",
    "                episode_title = episode.find(\"td\", {\"class\": \"summary\"}).find(\"a\")\n",
    "                if not episode_title:\n",
    "                    episode_title = episode.find(\"td\", {\"class\": \"summary\"}).contents[0]\n",
    "                else:\n",
    "                    episode_title = episode_title.contents[0]\n",
    "                episode_list.append(Episode(episode_title, episode_number))\n",
    "            season.episodes = episode_list\n",
    "            season_list.append(season)\n",
    "        self.seasons = season_list\n",
    "\n",
    "    def write_to_file_system(self):\n",
    "        directory = os.path.dirname(f'./{self.title}')\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            pass\n",
    "\n",
    "class Season:\n",
    "    \n",
    "    def __init__(self, number) -> None:\n",
    "        super().__init__()\n",
    "        self.number = number\n",
    "        self.episodes = []\n",
    "    \n",
    "    def get_episodes_json(self):\n",
    "        episodes = []\n",
    "        for episode in self.episodes:\n",
    "            episodes.append(episode.__str__())\n",
    "        return json.dumps(episodes)\n",
    "\n",
    "\n",
    "class Episode:\n",
    "\n",
    "    def __init__(self, title, number) -> None:\n",
    "        super().__init__()\n",
    "        self.title = title\n",
    "        self.number = number\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'episode:{self.number},  title:{self.title}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[SearchResult(title='List of Dexter episodes', url='https://en.wikipedia.org/wiki/List_of_Dexter_episodes')]\n"
     ]
    }
   ],
   "source": [
    "test = WikipediaSeries()\n",
    "result = test.search_by_name(\"Dexter\")\n",
    "print(result)\n",
    "soup = test.get_soup_by_url(result[0].url)\n",
    "#seasons = test.parse_seasons_from_soup(soup)\n",
    "test.parse_seasons_and_episodes_from_soup(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Season 1 (2006)\n./results/Dexter/Season 1 (2006)\nSeason 2 (2007)\n./results/Dexter/Season 2 (2007)\nSeason 3 (2008)\n./results/Dexter/Season 3 (2008)\nSeason 4 (2009)\n./results/Dexter/Season 4 (2009)\nSeason 5 (2010)\n./results/Dexter/Season 5 (2010)\nSeason 6 (2011)\n./results/Dexter/Season 6 (2011)\nSeason 7 (2012)\n./results/Dexter/Season 7 (2012)\nSeason 8 (2013)\n./results/Dexter/Season 8 (2013)\nSeason 1 (2009–10)\n./results/Dexter/Season 1 (2009–10)\nSeason 2: \n./results/Dexter/Season 2: \nSeason 3: \n./results/Dexter/Season 3: \n"
     ]
    }
   ],
   "source": [
    "for season in test.seasons:\n",
    "    print(season.number)\n",
    "    directory = os.path.dirname(f'./results/{test.title}/{season.number}/')\n",
    "    print(directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        with open(f'{directory}/episodes.json', 'w') as episodes_file: \n",
    "            episodes_file.write(season.get_episodes_json())\n",
    "        #with open('data.json', 'w', encoding='utf-8') as f:\n",
    "        #    json.dump(season.get_episodes_json(), f, ensure_ascii=False, indent=4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"episode:1,  title:Dexter\", \"episode:2,  title:Crocodile\", \"episode:3,  title:Popping Cherry\", \"episode:4,  title:Let's Give the Boy a Hand\", \"episode:5,  title:Love American Style\", \"episode:6,  title:Return to Sender\", \"episode:7,  title:Circle of Friends\", \"episode:8,  title:\\\"Shrink Wrap\\\"\", \"episode:9,  title:Father Knows Best\", \"episode:10,  title:Seeing Red\", \"episode:11,  title:Truth Be Told\", \"episode:12,  title:Born Free\"]\n------------------------------\n[\"episode:1,  title:It's Alive!\", \"episode:2,  title:Waiting to Exhale\", \"episode:3,  title:An Inconvenient Lie\", \"episode:4,  title:See-Through\", \"episode:5,  title:The Dark Defender\", \"episode:6,  title:Dex, Lies, and Videotape\", \"episode:7,  title:That Night, A Forest Grew\", \"episode:8,  title:Morning Comes\", \"episode:9,  title:Resistance Is Futile\", \"episode:10,  title:There's Something About Harry\", \"episode:11,  title:Left Turn Ahead\", \"episode:12,  title:The British Invasion\"]\n------------------------------\n[\"episode:1,  title:Our Father\", \"episode:2,  title:\\\"Finding Freebo\\\"\", \"episode:3,  title:\\\"The Lion Sleeps Tonight\\\"\", \"episode:4,  title:\\\"All In The Family\\\"\", \"episode:5,  title:\\\"Turning Biminese\\\"\", \"episode:6,  title:\\\"S\\u00ed Se Puede\\\"\", \"episode:7,  title:\\\"Easy As Pie\\\"\", \"episode:8,  title:The Damage A Man Can Do\", \"episode:9,  title:\\\"About Last Night\\\"\", \"episode:10,  title:\\\"Go Your Own Way\\\"\", \"episode:11,  title:\\\"I Had A Dream\\\"\", \"episode:12,  title:\\\"Do You Take Dexter Morgan?\\\"\"]\n------------------------------\n[\"episode:1,  title:\\\"Living The Dream\\\"\", \"episode:2,  title:\\\"Remains To Be Seen\\\"\", \"episode:3,  title:\\\"Blinded By The Light\\\"\", \"episode:4,  title:\\\"Dex Takes a Holiday\\\"\", \"episode:5,  title:\\\"Dirty Harry\\\"\", \"episode:6,  title:\\\"If I Had A Hammer\\\"\", \"episode:7,  title:\\\"Slack Tide\\\"\", \"episode:8,  title:\\\"Road Kill\\\"\", \"episode:9,  title:\\\"Hungry Man\\\"\", \"episode:10,  title:\\\"Lost Boys\\\"\", \"episode:11,  title:Hello, Dexter Morgan\", \"episode:12,  title:The Getaway\"]\n------------------------------\n[\"episode:1,  title:My Bad\", \"episode:2,  title:\\\"Hello, Bandit\\\"\", \"episode:3,  title:\\\"Practically Perfect\\\"\", \"episode:4,  title:\\\"Beauty and the Beast\\\"\", \"episode:5,  title:\\\"First Blood\\\"\", \"episode:6,  title:\\\"Everything is Illumenated\\\"\", \"episode:7,  title:\\\"Circle Us\\\"\", \"episode:8,  title:\\\"Take It!\\\"\", \"episode:9,  title:\\\"Teenage Wasteland\\\"\", \"episode:10,  title:\\\"In The Beginning\\\"\", \"episode:11,  title:\\\"Hop A Freighter\\\"\", \"episode:12,  title:The Big One\"]\n------------------------------\n[\"episode:1,  title:Those Kinds of Things\", \"episode:2,  title:\\\"Once Upon a Time...\\\"\", \"episode:3,  title:\\\"Smokey and the Bandit\\\"\", \"episode:4,  title:\\\"A Horse of a Different Color\\\"\", \"episode:5,  title:\\\"The Angel of Death\\\"\", \"episode:6,  title:\\\"Just Let Go\\\"\", \"episode:7,  title:\\\"Nebraska\\\"\", \"episode:8,  title:\\\"Sin of Omission\\\"\", \"episode:9,  title:\\\"Get Gellar\\\"\", \"episode:10,  title:\\\"Ricochet Rabbit\\\"\", \"episode:11,  title:\\\"Talk to the Hand\\\"\", \"episode:12,  title:This is the Way the World Ends\"]\n------------------------------\n[\"episode:1,  title:Are You...?\", \"episode:2,  title:\\\"Sunshine and Frosty Swirl\\\"\", \"episode:3,  title:\\\"Buck the System\\\"\", \"episode:4,  title:\\\"Run\\\"\", \"episode:5,  title:\\\"Swim Deep\\\"\", \"episode:6,  title:\\\"Do the Wrong Thing\\\"\", \"episode:7,  title:\\\"Chemistry\\\"\", \"episode:8,  title:\\\"Argentina\\\"\", \"episode:9,  title:\\\"Helter Skelter\\\"\", \"episode:10,  title:\\\"The Dark\\u2026 Whatever\\\"\", \"episode:11,  title:\\\"Do You See What I See?\\\"\", \"episode:12,  title:\\\"Surprise, Motherfucker!\\\"\"]\n------------------------------\n[\"episode:1,  title:\\\"A Beautiful Day\\\"\", \"episode:2,  title:\\\"Every Silver Lining...\\\"\", \"episode:3,  title:What's Eating Dexter Morgan?\", \"episode:4,  title:\\\"Scar Tissue\\\"\", \"episode:5,  title:\\\"This Little Piggy\\\"\", \"episode:6,  title:\\\"A Little Reflection\\\"\", \"episode:7,  title:\\\"Dress Code\\\"\", \"episode:8,  title:\\\"Are We There Yet?\\\"\", \"episode:9,  title:\\\"Make Your Own Kind of Music\\\"\", \"episode:10,  title:\\\"Goodbye Miami\\\"\", \"episode:11,  title:\\\"Monkey in a Box\\\"\", \"episode:12,  title:Remember the Monsters?\"]\n------------------------------\n[\"episode:\\\"Alex Timmons: Chapter One\\\",  title:\\\"Alex Timmons: Chapter One\\\"\", \"episode:\\\"Alex Timmons: Chapter Two\\\",  title:\\\"Alex Timmons: Chapter Two\\\"\", \"episode:\\\"Alex Timmons: Chapter Three\\\",  title:\\\"Alex Timmons: Chapter Three\\\"\", \"episode:\\\"Alex Timmons: Chapter Four\\\",  title:\\\"Alex Timmons: Chapter Four\\\"\", \"episode:\\\"Gene Marshall: Chapter One\\\",  title:\\\"Gene Marshall: Chapter One\\\"\", \"episode:\\\"Gene Marshall: Chapter Two\\\",  title:\\\"Gene Marshall: Chapter Two\\\"\", \"episode:\\\"Gene Marshall: Chapter Three\\\",  title:\\\"Gene Marshall: Chapter Three\\\"\", \"episode:\\\"Gene Marshall: Chapter Four\\\",  title:\\\"Gene Marshall: Chapter Four\\\"\", \"episode:\\\"Cindy Landon: Chapter One\\\",  title:\\\"Cindy Landon: Chapter One\\\"\", \"episode:\\\"Cindy Landon: Chapter Two\\\",  title:\\\"Cindy Landon: Chapter Two\\\"\", \"episode:\\\"Cindy Landon: Chapter Three\\\",  title:\\\"Cindy Landon: Chapter Three\\\"\", \"episode:\\\"Cindy Landon: Chapter Four\\\",  title:\\\"Cindy Landon: Chapter Four\\\"\"]\n------------------------------\n[\"episode:\\\"Dark Echo: Chapter One\\\",  title:\\\"Dark Echo: Chapter One\\\"\", \"episode:\\\"Dark Echo: Chapter Two\\\",  title:\\\"Dark Echo: Chapter Two\\\"\", \"episode:\\\"Dark Echo: Chapter Three\\\",  title:\\\"Dark Echo: Chapter Three\\\"\", \"episode:\\\"Dark Echo: Chapter Four\\\",  title:\\\"Dark Echo: Chapter Four\\\"\", \"episode:\\\"Dark Echo: Chapter Five\\\",  title:\\\"Dark Echo: Chapter Five\\\"\", \"episode:\\\"Dark Echo: Chapter Six\\\",  title:\\\"Dark Echo: Chapter Six\\\"\"]\n------------------------------\n[\"episode:\\\"All in the Family: Chapter 1\\\",  title:\\\"All in the Family: Chapter 1\\\"\", \"episode:\\\"All in the Family: Chapter 2\\\",  title:\\\"All in the Family: Chapter 2\\\"\", \"episode:\\\"All in the Family: Chapter 3\\\",  title:\\\"All in the Family: Chapter 3\\\"\", \"episode:\\\"All in the Family: Chapter 4\\\",  title:\\\"All in the Family: Chapter 4\\\"\", \"episode:\\\"All in the Family: Chapter 5\\\",  title:\\\"All in the Family: Chapter 5\\\"\", \"episode:\\\"All in the Family: Chapter 6\\\",  title:\\\"All in the Family: Chapter 6\\\"\"]\n------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print(test)\n",
    "directory = os.path.dirname(f'./{test.title')\n",
    "for season in test.seasons:\n",
    "    #print(season)\n",
    "    print(season.get_episodes_json())\n",
    "    #for episode in season.episodes:\n",
    "    #    print(episode)\n",
    "    print(\"---\" *10)\n",
    "    #print(season.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coloredlogs\n",
    "def setup_logging(level, config_file=None):\n",
    "    \"\"\"\n",
    "    Sets up the logging.\n",
    "\n",
    "    Needs the args to get the log level supplied\n",
    "\n",
    "    Args:\n",
    "        level: At which level do we log\n",
    "        config_file: Configuration to use\n",
    "\n",
    "    \"\"\"\n",
    "    # This will configure the logging, if the user has set a config file.\n",
    "    # If there's no config file, logging will default to stdout.\n",
    "    if config_file:\n",
    "        # Get the config for the logger. Of course this needs exception\n",
    "        # catching in case the file is not there and everything. Proper IO\n",
    "        # handling is not shown here.\n",
    "        try:\n",
    "            with open(config_file) as conf_file:\n",
    "                configuration = json.loads(conf_file.read())\n",
    "                # Configure the logger\n",
    "                logging.config.dictConfig(configuration)\n",
    "        except ValueError:\n",
    "            print(f'File \"{config_file}\" is not valid json, cannot continue.')\n",
    "            raise SystemExit(1)\n",
    "    else:\n",
    "        coloredlogs.install(level=level.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SearchResult(title='Ted Lasso', url='https://en.wikipedia.org/wiki/Ted_Lasso')\nSearchResult(title='Ted Lawson', url='https://en.wikipedia.org/wiki/Ted_Lawson')\nSearchResult(title='Tel Assor', url='https://en.wikipedia.org/wiki/Tel_Assor')\n"
     ]
    }
   ],
   "source": [
    "result = ['Ted Lasso', ['Ted Lasso', 'Ted Lawson', 'Tel Assor'], ['', '', ''], ['https://en.wikipedia.org/wiki/Ted_Lasso', 'https://en.wikipedia.org/wiki/Ted_Lawson', 'https://en.wikipedia.org/wiki/Tel_Assor']]\n",
    "\n",
    "for item in zip(result[1], result[3]):\n",
    "    print(SearchResult(*item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-26 15:55:05 sbpltg1b3hv2j urllib3.connectionpool[54960] DEBUG Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "https://en.wikipedia.org/wiki/List_of_Game_of_Thrones_episodes\n",
      "2021-02-26 15:55:05 sbpltg1b3hv2j urllib3.connectionpool[54960] DEBUG https://en.wikipedia.org:443 \"GET /wiki/List_of_Game_of_Thrones_episodes HTTP/1.1\" 200 51883\n",
      "['Series overview']\n",
      "['Season']\n",
      "['Episodes']\n",
      "['Originally aired']\n",
      "[<abbr title=\"Average\">Avg.</abbr>, ' U.S. viewers', <br/>, '(millions)']\n",
      "['First aired']\n",
      "['Last aired']\n",
      "[<a href=\"#Season_1_(2011)\">1</a>]\n",
      "['1']\n",
      "[<a href=\"#Season_2_(2012)\">2</a>]\n",
      "['2']\n",
      "[<a href=\"#Season_3_(2013)\">3</a>]\n",
      "['3']\n",
      "[<a href=\"#Season_4_(2014)\">4</a>]\n",
      "['4']\n",
      "[<a href=\"#Season_5_(2015)\">5</a>]\n",
      "['5']\n",
      "[<a href=\"#Season_6_(2016)\">6</a>]\n",
      "['6']\n",
      "[<a href=\"#Season_7_(2017)\">7</a>]\n",
      "['7']\n",
      "[<a href=\"#Season_8_(2019)\">8</a>]\n",
      "['8']\n"
     ]
    }
   ],
   "source": [
    "print(result[0].url)\n",
    "html_response = requests.get(result[0].url)\n",
    "soup = BeautifulSoup(html_response.text, 'html.parser')\n",
    "test = soup.find_all(\"span\", {\"class\": \"mw-headline\"})\n",
    "for soup_result in test:\n",
    "    if soup_result.string == \"Series overview\":\n",
    "        print(soup_result.contents)\n",
    "        table = soup_result.find_next(\"table\", {\"class\": \"wikitable plainrowheaders\"})\n",
    "        seasons = table.find_all(\"th\")\n",
    "        for season in seasons:\n",
    "            print(season.contents)\n",
    "            theseason = season.find(\"a\")\n",
    "            if theseason:\n",
    "                print(theseason.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<a href=\"#Season_1_(2006)\">1</a>, <a href=\"#Season_2_(2007)\">2</a>, <a href=\"#Season_3_(2008)\">3</a>, <a href=\"#Season_4_(2009)\">4</a>, <a href=\"#Season_5_(2010)\">5</a>, <a href=\"#Season_6_(2011)\">6</a>, <a href=\"#Season_7_(2012)\">7</a>, <a href=\"#Season_8_(2013)\">8</a>]\n"
     ]
    }
   ],
   "source": [
    "print(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-26 15:59:25 sbpltg1b3hv2j urllib3.connectionpool[54960] DEBUG Starting new HTTPS connection (1): en.wikipedia.org:443\n",
      "2021-02-26 15:59:25 sbpltg1b3hv2j urllib3.connectionpool[54960] DEBUG https://en.wikipedia.org:443 \"GET /wiki/List_of_Dexter_episodes HTTP/1.1\" 200 43265\n",
      "['Season']\n",
      "['Episodes']\n",
      "['Originally aired']\n",
      "['First aired']\n",
      "['Last aired']\n",
      "[<a href=\"#Season_1_(2006)\">1</a>]\n",
      "['1']\n",
      "[<a href=\"#Season_2_(2007)\">2</a>]\n",
      "['2']\n",
      "[<a href=\"#Season_3_(2008)\">3</a>]\n",
      "['3']\n",
      "[<a href=\"#Season_4_(2009)\">4</a>]\n",
      "['4']\n",
      "[<a href=\"#Season_5_(2010)\">5</a>]\n",
      "['5']\n",
      "[<a href=\"#Season_6_(2011)\">6</a>]\n",
      "['6']\n",
      "[<a href=\"#Season_7_(2012)\">7</a>]\n",
      "['7']\n",
      "[<a href=\"#Season_8_(2013)\">8</a>]\n",
      "['8']\n"
     ]
    }
   ],
   "source": [
    "html_response = requests.get(result[0].url)\n",
    "soup = BeautifulSoup(html_response.text, 'html.parser')\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable plainrowheaders\"})\n",
    "seasons = table.find_all(\"th\")\n",
    "for season in seasons:\n",
    "    print(season.contents)\n",
    "    theseason = season.find(\"a\")\n",
    "    if theseason:\n",
    "        print(theseason.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<table class=\"wikitable plainrowheaders\" style=\"text-align:center\"><tbody><tr style=\"text-align:center\"><th colspan=\"2\" rowspan=\"2\" scope=\"col\" style=\"min-width:50px;padding:0 8px\">Season</th><th colspan=\"2\" rowspan=\"2\" scope=\"col\" style=\"padding:0 8px\">Episodes</th><th colspan=\"2\" scope=\"col\">Originally aired</th><th rowspan=\"2\" scope=\"col\" style=\"padding:0 8px\"><abbr title=\"Average\">Avg.</abbr> U.S. viewers<br/>(millions)</th></tr><tr><th scope=\"col\">First aired</th><th scope=\"col\">Last aired</th></tr><tr><td style=\"background:#295354;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_1_(2011)\">1</a></th><td colspan=\"2\">10</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">April 17, 2011<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2011-04-17</span>)</span></td><td style=\"padding:0 8px\">June 19, 2011<span style=\"display:none\"> (<span class=\"dtend\">2011-06-19</span>)</span></td><td>2.52<sup class=\"reference\" id=\"cite_ref-average_2_13-0\"><a href=\"#cite_note-average_2-13\">[13]</a></sup></td></tr><tr><td style=\"background:#D09916;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_2_(2012)\">2</a></th><td colspan=\"2\">10</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">April 1, 2012<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2012-04-01</span>)</span></td><td style=\"padding:0 8px\">June 3, 2012<span style=\"display:none\"> (<span class=\"dtend\">2012-06-03</span>)</span></td><td>3.80<sup class=\"reference\" id=\"cite_ref-average_2_13-1\"><a href=\"#cite_note-average_2-13\">[13]</a></sup></td></tr><tr><td style=\"background:#54575A;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_3_(2013)\">3</a></th><td colspan=\"2\">10</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">March 31, 2013<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2013-03-31</span>)</span></td><td style=\"padding:0 8px\">June 9, 2013<span style=\"display:none\"> (<span class=\"dtend\">2013-06-09</span>)</span></td><td>4.97<sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup></td></tr><tr><td style=\"background:#222222;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_4_(2014)\">4</a></th><td colspan=\"2\">10</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">April 6, 2014<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2014-04-06</span>)</span></td><td style=\"padding:0 8px\">June 15, 2014<span style=\"display:none\"> (<span class=\"dtend\">2014-06-15</span>)</span></td><td>6.84<sup class=\"reference\" id=\"cite_ref-15\"><a href=\"#cite_note-15\">[15]</a></sup></td></tr><tr><td style=\"background:#68411C;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_5_(2015)\">5</a></th><td colspan=\"2\">10</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">April 12, 2015<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2015-04-12</span>)</span></td><td style=\"padding:0 8px\">June 14, 2015<span style=\"display:none\"> (<span class=\"dtend\">2015-06-14</span>)</span></td><td>6.88<sup class=\"reference\" id=\"cite_ref-16\"><a href=\"#cite_note-16\">[16]</a></sup></td></tr><tr><td style=\"background:#31485C;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_6_(2016)\">6</a></th><td colspan=\"2\">10</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">April 24, 2016<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2016-04-24</span>)</span></td><td style=\"padding:0 8px\">June 26, 2016<span style=\"display:none\"> (<span class=\"dtend\">2016-06-26</span>)</span></td><td>7.69<sup class=\"reference\" id=\"cite_ref-17\"><a href=\"#cite_note-17\">[17]</a></sup></td></tr><tr><td style=\"background:#091411;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_7_(2017)\">7</a></th><td colspan=\"2\">7</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">July 16, 2017<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2017-07-16</span>)</span></td><td style=\"padding:0 8px\">August 27, 2017<span style=\"display:none\"> (<span class=\"dtend\">2017-08-27</span>)</span></td><td>10.26<sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[18]</a></sup></td></tr><tr><td style=\"background:#3D424A;width:10px\"></td><th colspan=\"1\" scope=\"row\" style=\"text-align:center\"><a href=\"#Season_8_(2019)\">8</a></th><td colspan=\"2\">6</td><td colspan=\"1\" style=\"padding:0.2em 0.4em\">April 14, 2019<span style=\"display:none\"> (<span class=\"bday dtstart published updated\">2019-04-14</span>)</span></td><td style=\"padding:0 8px\">May 19, 2019<span style=\"display:none\"> (<span class=\"dtend\">2019-05-19</span>)</span></td><td>11.99<sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup></td></tr></tbody></table>\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('wiki_parser': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "49268e1026196618a97305a1c77706a44b039a3be2b479f82fad0271988ebd54"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}