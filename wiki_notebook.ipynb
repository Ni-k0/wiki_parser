{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass\n",
    "from configuration import (\n",
    "    WIKIPEDIA_HOST_URL,\n",
    "    WIKIPEDIA_SEARCH_API\n",
    ")\n",
    "\n",
    "LOGGER_BASENAME = 'wikisearch'\n",
    "LOGGER = logging.getLogger(LOGGER_BASENAME)\n",
    "LOGGER.addHandler(logging.NullHandler())\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class LoggerMixin(object):\n",
    "    def __init__(self) -> None:\n",
    "        self._logger = logging.getLogger(f'{LOGGER_BASENAME}.{self.__class__.__name__}')\n",
    "\n",
    "class WikipediaSeries(LoggerMixin):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.search_url = WIKIPEDIA_SEARCH_API\n",
    "        self.seasons = []\n",
    "        self.title = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'series seasons: {self.seasons}'\n",
    "    \n",
    "    def _get_query_map(self, name):\n",
    "        query_map = {\n",
    "            'episode_list': f'list of {name} episodes',\n",
    "            'miniseries': f'{name} miniseries',\n",
    "            'name': f'{name}'\n",
    "        }\n",
    "        return query_map\n",
    "\n",
    "    def search_by_name(self, name):\n",
    "        for type, query in self._get_query_map(name).items():\n",
    "            self._logger.debug(f'Searching for {name} with type:{type}')\n",
    "            result = self._search(query)\n",
    "            if result:\n",
    "                if len(result) == 1:\n",
    "                    self.title = name\n",
    "                return result\n",
    "    \n",
    "    def _search(self, query):\n",
    "        parameters = {'action': 'opensearch',\n",
    "                            'format': 'json',\n",
    "                            'formatversion': '2',\n",
    "                            'search': query}\n",
    "\n",
    "        response = requests.get(self.search_url, params=parameters)\n",
    "        if response.ok:\n",
    "            return [SearchResult(*args) for args in zip(response.json()[1], response.json()[3])]\n",
    "        else:\n",
    "            self._logger.error(f'Request failed with code {response.code} and message {response.text}')\n",
    "        \n",
    "    \n",
    "    def get_soup_by_url(self, url):\n",
    "        html_response = requests.get(url)\n",
    "        soup = BeautifulSoup(html_response.text, 'html.parser')\n",
    "        return soup\n",
    "    \n",
    "    def parse_seasons_from_soup(self, soup):\n",
    "        season_list = []\n",
    "        table = soup.find(\"table\", {\"class\": \"wikitable plainrowheaders\"})\n",
    "        t_headers = table.find_all(\"th\")\n",
    "        for header in t_headers:\n",
    "            season = header.find(\"a\")\n",
    "            if season:\n",
    "                season_list.append(season.contents[0])\n",
    "        return season_list\n",
    "\n",
    "    def parse_seasons_and_episodes_from_soup(self, soup):\n",
    "        season_list = []\n",
    "        tables = soup.find_all(\"table\", {\"class\": \"wikitable plainrowheaders wikiepisodetable\"})\n",
    "        for table in tables:\n",
    "            episode_list = []\n",
    "            season_header = table.find_previous_sibling('h3')\n",
    "            season_title = season_header.find(\"span\", {\"class\": \"mw-headline\"}).contents[0]\n",
    "            season = Season(season_title)\n",
    "            episodes = table.find_all(\"tr\", {\"class\": \"vevent\"})\n",
    "            for episode in episodes:\n",
    "                episode_number = episode.find(\"td\").contents[0]\n",
    "                episode_title = episode.find(\"td\", {\"class\": \"summary\"}).find(\"a\")\n",
    "                if not episode_title:\n",
    "                    episode_title = episode.find(\"td\", {\"class\": \"summary\"}).contents[0]\n",
    "                else:\n",
    "                    episode_title = episode_title.contents[0]\n",
    "                episode_list.append(Episode(episode_title, episode_number))\n",
    "            season.episodes = episode_list\n",
    "            season_list.append(season)\n",
    "        self.seasons = season_list\n",
    "\n",
    "    def write_to_file_system(self):\n",
    "        directory = os.path.dirname(f'./{self.title}')\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            pass\n",
    "\n",
    "class Season:\n",
    "    \n",
    "    def __init__(self, number) -> None:\n",
    "        super().__init__()\n",
    "        self.number = number\n",
    "        self.episodes = []\n",
    "    \n",
    "    def get_episodes_json(self):\n",
    "        episodes = []\n",
    "        for episode in self.episodes:\n",
    "            episodes.append(episode.__str__())\n",
    "        return json.dumps(episodes)\n",
    "\n",
    "\n",
    "class Episode:\n",
    "\n",
    "    def __init__(self, title, number) -> None:\n",
    "        super().__init__()\n",
    "        self.title = title\n",
    "        self.number = number\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'episode:{self.number},  title:{self.title}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WikipediaSeries()\n",
    "result = test.search_by_name(\"Billions\")\n",
    "print(result)\n",
    "soup = test.get_soup_by_url(result[0].url)\n",
    "test.parse_seasons_and_episodes_from_soup(soup)\n",
    "test.write_to_file_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season in test.seasons:\n",
    "    print(season.number)\n",
    "    directory = os.path.dirname(f'./results/{test.title}/{season.number}/')\n",
    "    print(directory)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        with open(f'{directory}/episodes.json', 'w') as episodes_file: \n",
    "            episodes_file.write(season.get_episodes_json())\n",
    "        #with open('data.json', 'w', encoding='utf-8') as f:\n",
    "        #    json.dump(season.get_episodes_json(), f, ensure_ascii=False, indent=4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test)\n",
    "directory = os.path.dirname(f'./{test.title')\n",
    "for season in test.seasons:\n",
    "    #print(season)\n",
    "    print(season.get_episodes_json())\n",
    "    #for episode in season.episodes:\n",
    "    #    print(episode)\n",
    "    print(\"---\" *10)\n",
    "    #print(season.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coloredlogs\n",
    "def setup_logging(level, config_file=None):\n",
    "    \"\"\"\n",
    "    Sets up the logging.\n",
    "\n",
    "    Needs the args to get the log level supplied\n",
    "\n",
    "    Args:\n",
    "        level: At which level do we log\n",
    "        config_file: Configuration to use\n",
    "\n",
    "    \"\"\"\n",
    "    # This will configure the logging, if the user has set a config file.\n",
    "    # If there's no config file, logging will default to stdout.\n",
    "    if config_file:\n",
    "        # Get the config for the logger. Of course this needs exception\n",
    "        # catching in case the file is not there and everything. Proper IO\n",
    "        # handling is not shown here.\n",
    "        try:\n",
    "            with open(config_file) as conf_file:\n",
    "                configuration = json.loads(conf_file.read())\n",
    "                # Configure the logger\n",
    "                logging.config.dictConfig(configuration)\n",
    "        except ValueError:\n",
    "            print(f'File \"{config_file}\" is not valid json, cannot continue.')\n",
    "            raise SystemExit(1)\n",
    "    else:\n",
    "        coloredlogs.install(level=level.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ['Ted Lasso', ['Ted Lasso', 'Ted Lawson', 'Tel Assor'], ['', '', ''], ['https://en.wikipedia.org/wiki/Ted_Lasso', 'https://en.wikipedia.org/wiki/Ted_Lawson', 'https://en.wikipedia.org/wiki/Tel_Assor']]\n",
    "\n",
    "for item in zip(result[1], result[3]):\n",
    "    print(SearchResult(*item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0].url)\n",
    "html_response = requests.get(result[0].url)\n",
    "soup = BeautifulSoup(html_response.text, 'html.parser')\n",
    "test = soup.find_all(\"span\", {\"class\": \"mw-headline\"})\n",
    "for soup_result in test:\n",
    "    if soup_result.string == \"Series overview\":\n",
    "        print(soup_result.contents)\n",
    "        table = soup_result.find_next(\"table\", {\"class\": \"wikitable plainrowheaders\"})\n",
    "        seasons = table.find_all(\"th\")\n",
    "        for season in seasons:\n",
    "            print(season.contents)\n",
    "            theseason = season.find(\"a\")\n",
    "            if theseason:\n",
    "                print(theseason.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_response = requests.get(result[0].url)\n",
    "soup = BeautifulSoup(html_response.text, 'html.parser')\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable plainrowheaders\"})\n",
    "seasons = table.find_all(\"th\")\n",
    "for season in seasons:\n",
    "    print(season.contents)\n",
    "    theseason = season.find(\"a\")\n",
    "    if theseason:\n",
    "        print(theseason.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('wiki_parser': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "0422c6a65492cf3013b3d726380bb2f26fdab722032632d6e793798fbb3fe670"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}